{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dde641e",
   "metadata": {},
   "source": [
    "# Logistic Regression for Expected Goals (xG) Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d153b594",
   "metadata": {},
   "source": [
    "This notebook applies a **Logistic Regression model** to estimate **expected goals (xG)** using dataset **DS3**. The aim is to assign to each shot the probability of resulting in a goal. Although Logistic Regression is formally a classification method, it is the traditional baseline in football analytics for xG modeling, since it naturally provides a probability between 0 and 1 that can be interpreted as the xG value.\n",
    "\n",
    "Logistic Regression is an appropriate starting point because it is **simple and widely established** in the literature. The coefficients can be inspected directly to evaluate the contribution of each feature, while the model itself is capable of producing **well-calibrated probabilities** when properly trained. This makes it a natural benchmark for comparing more complex approaches such as Random Forest, XGBoost, or Neural Networks.\n",
    "\n",
    "The following metrics are used to ensure the evaluation:\n",
    "\n",
    "- **Brier Score**, measuring the mean squared error of probabilistic predictions.  \n",
    "\n",
    "- **Log Loss**, rewarding correct calibration and penalizing confident but wrong predictions.  \n",
    "\n",
    "- **RMSE (Root Mean Squared Error)** and **MAE (Mean Absolute Error)**, providing complementary regression error measures.  \n",
    "\n",
    "- **Calibration Curve (Reliability Diagram)**, offering a graphical evaluation of the alignment between predicted probabilities and observed outcomes.\n",
    "\n",
    "This model therefore serves as a transparent and interpretable **baseline**, against which more advanced models will later be compared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f08d558",
   "metadata": {},
   "source": [
    "#### Imports and Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8e401e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Ready to load data.\n"
     ]
    }
   ],
   "source": [
    "#  Imports and global settings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    brier_score_loss,\n",
    "    log_loss,\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error\n",
    ")\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "\n",
    "# Display options\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.float_format\", lambda x: f\"{x:,.4f}\")\n",
    "\n",
    "\n",
    "# Output paths\n",
    "OUTPUT_DIR = \"../task1_xg/outputs/04_logreg\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Setup complete. Ready to load data.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a3368e",
   "metadata": {},
   "source": [
    "#### Load Dataset DS3 and train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfc6851e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 2 rows, 1 columns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['version https://git-lfs.github.com/spec/v1']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "DATA_PATH = \"../task1_xg/data/DS3.csv\" \n",
    "ds3 = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(f\"Dataset loaded: {ds3.shape[0]} rows, {ds3.shape[1]} columns\")\n",
    "ds3.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0f6f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "target_column = \"target_xg\"  # expected goals column\n",
    "train_columns = [col for col in ds3.columns if col != target_column]\n",
    "\n",
    "X = ds3[train_columns]\n",
    "y = ds3[target_column]\n",
    "\n",
    "# Sanity check on target\n",
    "print(\"\\nTarget (xG) stats:\")\n",
    "print(y.describe())\n",
    "print(f\"Range: {y.min():.4f} - {y.max():.4f}\")\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=(y > 0).astype(int)\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape[0]} rows\")\n",
    "print(f\"Test set: {X_test.shape[0]} rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91719c53",
   "metadata": {},
   "source": [
    "####  Logistic Regression: training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf7db81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics function\n",
    "def evaluate_predictions(y_true, y_pred, model_name=\"Model\"):\n",
    "    metrics = {\n",
    "        \"Brier\": brier_score_loss(y_true, y_pred),\n",
    "        \"LogLoss\": log_loss(y_true, y_pred, eps=1e-15),\n",
    "        \"RMSE\": mean_squared_error(y_true, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred)\n",
    "    }\n",
    "    print(f\"\\n{model_name} performance:\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"{k:>8}: {v:.4f}\")\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be1eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "log_reg = LogisticRegression(\n",
    "    penalty=\"l2\",               # regularization\n",
    "    C=1.0,                      # inverse of regularization strength\n",
    "    solver=\"lbfgs\",             # efficient solver for small/medium datasets\n",
    "    max_iter=1000,              # to ensure convergence\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities (xG values)\n",
    "y_train_pred = log_reg.predict_proba(X_train)[:, 1]\n",
    "y_test_pred = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate\n",
    "logreg_train_metrics = evaluate_predictions(y_train, y_train_pred, \"Logistic Regression (train)\")\n",
    "logreg_test_metrics = evaluate_predictions(y_test, y_test_pred, \"Logistic Regression (test)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
