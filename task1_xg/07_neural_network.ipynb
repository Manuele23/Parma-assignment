{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d20779fb",
   "metadata": {},
   "source": [
    "# Neural Network Regressor for Expected Goal (xG) Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a108f2",
   "metadata": {},
   "source": [
    "To further extend the modeling pipeline, we train a **Neural Network (NN) Regressor** on dataset DS4.  \n",
    "\n",
    "Unlike tree-based models, Neural Networks can learn **complex non-linear interactions** between features through multiple hidden layers and activation functions. They are particularly effective when relationships among features are subtle or high-dimensional, although they require more careful **regularization** to avoid overfitting.  \n",
    "\n",
    "The chosen NN architecture includes: \n",
    "\n",
    "- **Input layer** matching the number of features.  \n",
    "\n",
    "- **Hidden layers** with ReLU activation to capture non-linear patterns.  \n",
    "\n",
    "- **Dropout layers** for regularization and overfitting prevention.  \n",
    "\n",
    "- **Output layer** with a single neuron to predict the continuous xG value in [0,1].  \n",
    "\n",
    "The model is trained using the **Adam optimizer** and **Mean Squared Error (MSE)** loss, with **early stopping** applied to prevent overfitting.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c416eeb6",
   "metadata": {},
   "source": [
    "#### Imports and Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33414c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Ready to load data.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "\n",
    "# Display options\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.float_format\", lambda x: f\"{x:,.4f}\")\n",
    "\n",
    "# Output paths\n",
    "OUTPUT_DIR = \"../task1_xg/outputs\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Model directory\n",
    "MODEL_DIR = \"../task1_xg/models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Setup complete. Ready to load data.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2b1e7d",
   "metadata": {},
   "source": [
    "#### Load Dataset DS4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfa3db70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 86833 rows, 26 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>period</th>\n",
       "      <th>shot_type</th>\n",
       "      <th>shot_technique</th>\n",
       "      <th>shot_body_part</th>\n",
       "      <th>play_pattern</th>\n",
       "      <th>under_pressure</th>\n",
       "      <th>shot_first_time</th>\n",
       "      <th>shot_one_on_one</th>\n",
       "      <th>target_xg</th>\n",
       "      <th>loc_x</th>\n",
       "      <th>loc_y</th>\n",
       "      <th>end_shot_x</th>\n",
       "      <th>end_shot_y</th>\n",
       "      <th>end_shot_z</th>\n",
       "      <th>end_shot_z_available</th>\n",
       "      <th>shot_from_set_piece</th>\n",
       "      <th>distance_to_goal</th>\n",
       "      <th>angle_to_goal</th>\n",
       "      <th>gender</th>\n",
       "      <th>role</th>\n",
       "      <th>num_players_between</th>\n",
       "      <th>closest_defender_dist</th>\n",
       "      <th>goalkeeper_positioning</th>\n",
       "      <th>free_proj_goal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.8136</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0566</td>\n",
       "      <td>0.7774</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.6561</td>\n",
       "      <td>0.4393</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.2143</td>\n",
       "      <td>0.1293</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3077</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.7132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0507</td>\n",
       "      <td>0.6780</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1434</td>\n",
       "      <td>0.9347</td>\n",
       "      <td>0.4166</td>\n",
       "      <td>0.9645</td>\n",
       "      <td>0.4456</td>\n",
       "      <td>0.1364</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0871</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.3670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0797</td>\n",
       "      <td>0.1356</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>0.8416</td>\n",
       "      <td>0.6964</td>\n",
       "      <td>0.8766</td>\n",
       "      <td>0.5845</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.2227</td>\n",
       "      <td>0.0865</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1538</td>\n",
       "      <td>0.0329</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.5547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0942</td>\n",
       "      <td>0.2712</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0528</td>\n",
       "      <td>0.9269</td>\n",
       "      <td>0.5910</td>\n",
       "      <td>0.8897</td>\n",
       "      <td>0.5845</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.5316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1159</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.6534</td>\n",
       "      <td>0.5295</td>\n",
       "      <td>0.6523</td>\n",
       "      <td>0.5156</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.3301</td>\n",
       "      <td>0.0872</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2308</td>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.7198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   minute  second  period  shot_type  shot_technique  shot_body_part  \\\n",
       "0  0.0435  0.8136       2          3               1               3   \n",
       "1  0.0507  0.6780       2          3               1               1   \n",
       "2  0.0797  0.1356       2          3               1               1   \n",
       "3  0.0942  0.2712       2          3               1               0   \n",
       "4  0.1159  0.0000       2          3               1               1   \n",
       "\n",
       "   play_pattern  under_pressure  shot_first_time  shot_one_on_one  target_xg  \\\n",
       "0             2           False             True            False     0.0566   \n",
       "1             1            True             True            False     0.1434   \n",
       "2             2           False             True            False     0.0382   \n",
       "3             2           False            False            False     0.0528   \n",
       "4             1            True            False            False     0.0213   \n",
       "\n",
       "   loc_x  loc_y  end_shot_x  end_shot_y  end_shot_z  end_shot_z_available  \\\n",
       "0 0.7774 0.4366      0.6561      0.4393      0.0000                 False   \n",
       "1 0.9347 0.4166      0.9645      0.4456      0.1364                  True   \n",
       "2 0.8416 0.6964      0.8766      0.5845      0.0000                 False   \n",
       "3 0.9269 0.5910      0.8897      0.5845      0.0000                 False   \n",
       "4 0.6534 0.5295      0.6523      0.5156      0.0000                 False   \n",
       "\n",
       "   shot_from_set_piece  distance_to_goal  angle_to_goal  gender  role  \\\n",
       "0                False            0.2143         0.1293       1     3   \n",
       "1                False            0.0871         0.2250       1     0   \n",
       "2                False            0.2227         0.0865       1     0   \n",
       "3                False            0.0995         0.1940       1     0   \n",
       "4                False            0.3301         0.0872       1     3   \n",
       "\n",
       "   num_players_between  closest_defender_dist  goalkeeper_positioning  \\\n",
       "0               0.3077                 0.0104                  0.0132   \n",
       "1               0.0769                 0.0079                  0.0123   \n",
       "2               0.1538                 0.0329                  0.0068   \n",
       "3               0.0769                 0.0071                  0.0045   \n",
       "4               0.2308                 0.0208                  0.0019   \n",
       "\n",
       "   free_proj_goal  \n",
       "0          0.7132  \n",
       "1          0.3670  \n",
       "2          0.5547  \n",
       "3          0.5316  \n",
       "4          0.7198  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"../task1_xg/data/DS4.csv\" \n",
    "ds4 = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(f\"Dataset loaded: {ds4.shape[0]} rows, {ds4.shape[1]} columns\")\n",
    "ds4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fa2c85",
   "metadata": {},
   "source": [
    "####  Define features, target and train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa05f674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target (xG) stats:\n",
      "count   86,833.0000\n",
      "mean         0.0973\n",
      "std          0.1281\n",
      "min          0.0002\n",
      "25%          0.0275\n",
      "50%          0.0540\n",
      "75%          0.1060\n",
      "max          0.9951\n",
      "Name: target_xg, dtype: float64\n",
      "Range: 0.0002 - 0.9951\n",
      "\n",
      "Training set: 69466 rows\n",
      "Test set: 17367 rows\n"
     ]
    }
   ],
   "source": [
    "target_column = \"target_xg\"  # expected goals column\n",
    "train_columns = [col for col in ds4.columns if col != target_column]\n",
    "\n",
    "X = ds4[train_columns]\n",
    "y = ds4[target_column]\n",
    "\n",
    "# Sanity check on target\n",
    "print(\"\\nTarget (xG) stats:\")\n",
    "print(y.describe())\n",
    "print(f\"Range: {y.min():.4f} - {y.max():.4f}\")\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape[0]} rows\")\n",
    "print(f\"Test set: {X_test.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fc696c",
   "metadata": {},
   "source": [
    "#### Training the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc21a5d4",
   "metadata": {},
   "source": [
    "To extend the analysis to a neural approach, a **Multi-Layer Perceptron (MLP) Regressor** is trained on dataset DS4.  \n",
    "\n",
    "A **RandomizedSearchCV with 5-fold cross-validation** is employed to efficiently identify the best hyperparameters, optimizing for **Root Mean Squared Error (RMSE)** as the main evaluation metric.  \n",
    "\n",
    "Unlike GridSearchCV, RandomizedSearchCV samples only a fixed number of configurations from the defined search space. This approach makes the process faster and computationally lighter, while still exploring a diverse range of parameter combinations.  \n",
    "It therefore represents a **trade-off between exploration and efficiency**: the absolute best configuration may not be guaranteed, but the method provides a very good solution with far fewer evaluations, saving substantial time and resources.  \n",
    "\n",
    "The hyperparameters explored include:  \n",
    "\n",
    "- `hidden_layer_sizes`: architecture of the network, defining the number of neurons per hidden layer.  \n",
    "\n",
    "- `activation`: non-linear transformation applied at each neuron (`relu` or `tanh`).  \n",
    "\n",
    "- `alpha`: L2 regularization parameter, preventing overfitting by penalizing large weights.  \n",
    "\n",
    "- `learning_rate_init`: initial learning rate controlling the step size of weight updates.  \n",
    "\n",
    "- `solver`: optimization algorithm used for training (`adam` or `lbfgs`).  \n",
    "\n",
    "At the end of the search, the best model (`best_mlp`) is automatically retrained on the full training set with the selected hyperparameters, and is then used for prediction and evaluation on both the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36c6bb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manuelemustari/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:697: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/Users/manuelemustari/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:697: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/Users/manuelemustari/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:697: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/Users/manuelemustari/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:697: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/Users/manuelemustari/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:697: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/Users/manuelemustari/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:697: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/Users/manuelemustari/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:697: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/Users/manuelemustari/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:697: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time=   6.0s\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time=   6.0s\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time=   6.0s\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time=   6.0s\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time=   6.0s\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time=   6.0s\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time=   6.0s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 33\u001b[0m\n\u001b[1;32m     21\u001b[0m rand_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m     22\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mmlp,                          \u001b[38;5;66;03m# MLP model\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mparam_dist,         \u001b[38;5;66;03m# parameter distributions for hyperparameter tuning\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m                               \u001b[38;5;66;03m# verbosity level, defines the amount of information displayed during training\u001b[39;00m\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Fit\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[43mrand_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Best model\u001b[39;00m\n\u001b[1;32m     36\u001b[0m best_mlp \u001b[38;5;241m=\u001b[39m rand_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1015\u001b[0m     )\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_search.py:1960\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1958\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1959\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1960\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1962\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1963\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    962\u001b[0m         )\n\u001b[1;32m    963\u001b[0m     )\n\u001b[0;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    988\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Base model\n",
    "mlp = MLPRegressor(\n",
    "    max_iter=1000,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=20,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Parameter grid\n",
    "param_dist = {\n",
    "    \"hidden_layer_sizes\": [(64,), (128,), (64, 32), (128, 64)],\n",
    "    \"activation\": [\"relu\", \"tanh\"],\n",
    "    \"alpha\": [1e-5, 1e-4, 1e-3],          # L2 regularization\n",
    "    \"learning_rate_init\": [0.001, 0.01],  # initial learning rate\n",
    "    \"solver\": [\"adam\"]           # optimizers\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV\n",
    "rand_search = RandomizedSearchCV(\n",
    "    estimator=mlp,                          # MLP model\n",
    "    param_distributions=param_dist,         # parameter distributions for hyperparameter tuning\n",
    "    n_iter=100,                             # number of random combinations to try\n",
    "    scoring=\"neg_root_mean_squared_error\",  # RMSE as main metric (neg because of sklearn convention)\n",
    "    cv=5,                                   # cross-validation splitting strategy\n",
    "    random_state=RANDOM_STATE,              # reproducibility\n",
    "    n_jobs=-1,                              # parallelization\n",
    "    verbose=2                               # verbosity level, defines the amount of information displayed during training\n",
    ")\n",
    "\n",
    "# Fit\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_mlp = rand_search.best_estimator_\n",
    "print(\"\\nBest parameters found:\", rand_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1199f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(y_true, y_pred, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Evaluate regression performance using a set of metrics\n",
    "    suitable for probabilistic xG estimation (continuous target in [0, 1]).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like\n",
    "        Ground truth (true xG values).\n",
    "    y_pred : array-like\n",
    "        Predicted xG values.\n",
    "    model_name : str\n",
    "        Label to display in output.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    metrics : dict\n",
    "        Dictionary of metric values.\n",
    "    \"\"\"\n",
    "\n",
    "    metrics = {\n",
    "        # Root Mean Squared Error (RMSE):\n",
    "        # sqrt( (1/n) * Σ (y_i - ŷ_i)^2 )\n",
    "        # Penalizes large errors more strongly; same units as target.\n",
    "        \"RMSE\": root_mean_squared_error(y_true, y_pred),\n",
    "\n",
    "        # Mean Absolute Error (MAE):\n",
    "        # (1/n) * Σ |y_i - ŷ_i|\n",
    "        # Robust to outliers; easy to interpret as \"average absolute error\".\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "\n",
    "        # Coefficient of Determination (R²):\n",
    "        # 1 - (Σ (y_i - ŷ_i)^2) / (Σ (y_i - ȳ)^2)\n",
    "        # Measures proportion of variance explained by the model.\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "\n",
    "        # Pearson Correlation Coefficient:\n",
    "        # cov(y, ŷ) / (σ_y * σ_ŷ)\n",
    "        # Measures strength of linear relationship between y_true and y_pred.\n",
    "        \"Pearson\": pearsonr(y_true, y_pred)[0],\n",
    "\n",
    "        # Spearman Rank Correlation:\n",
    "        # Pearson correlation between rank(y) and rank(ŷ)\n",
    "        # Captures monotonic (not necessarily linear) relationships.\n",
    "        \"Spearman\": spearmanr(y_true, y_pred)[0]\n",
    "    }\n",
    "\n",
    "    # Print nicely formatted results\n",
    "    print(f\"\\n{model_name} performance:\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"{k:>12}: {v:.4f}\")\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a319f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on train/test (clip to [0,1] as they are probabilities)\n",
    "y_train_pred = np.clip(best_mlp.predict(X_train), 0, 1)\n",
    "y_test_pred  = np.clip(best_mlp.predict(X_test),  0, 1)\n",
    "\n",
    "# Evaluate with the same function used across models\n",
    "train_metrics = evaluate_predictions(y_train, y_train_pred, \"Neural Network (train)\")\n",
    "test_metrics  = evaluate_predictions(y_test,  y_test_pred,  \"Neural Network (test)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a25c28",
   "metadata": {},
   "source": [
    "#### Features Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc8766c",
   "metadata": {},
   "source": [
    "Unlike Linear Regression, Random Forest, or XGBoost, a **Neural Network does not provide a straightforward feature importance measure**. The weights of the network cannot be directly interpreted as feature contributions, since they are distributed across multiple layers and transformed by non-linear activation functions.  \n",
    "\n",
    "For consistency and interpretability, **feature importance will only be reported for models that natively support it** (Linear Regression, Random Forest, XGBoost). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee0b39c",
   "metadata": {},
   "source": [
    "#### Save results and trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a4d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Save metrics\n",
    "results_df = pd.DataFrame(\n",
    "    [train_metrics, test_metrics],\n",
    "    index=[\"Neural Network (train)\", \"Neural Network (test)\"]\n",
    ")\n",
    "results_df.to_csv(f\"{OUTPUT_DIR}/metrics_nn.csv\", index=True)\n",
    "\n",
    "# Save model\n",
    "model_path = f\"{MODEL_DIR}/model_nn.pkl\"\n",
    "joblib.dump(best_mlp, model_path)\n",
    "\n",
    "print(f\"Metrics saved to {OUTPUT_DIR}/metrics_nn.csv\")\n",
    "print(f\"Model saved to {model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f414a61b",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e12f433",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
