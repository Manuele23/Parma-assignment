{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d20779fb",
   "metadata": {},
   "source": [
    "# Neural Network Regressor for Expected Goal (xG) Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a108f2",
   "metadata": {},
   "source": [
    "To further extend the modeling pipeline, we train a **Neural Network (NN) Regressor** on dataset DS4.  \n",
    "\n",
    "Unlike tree-based models, Neural Networks can learn **complex non-linear interactions** between features through multiple hidden layers and activation functions. They are particularly effective when relationships among features are subtle or high-dimensional, although they require more careful **regularization** to avoid overfitting.  \n",
    "\n",
    "The chosen NN architecture includes: \n",
    "\n",
    "- **Input layer** matching the number of features.  \n",
    "\n",
    "- **Hidden layers** with ReLU activation to capture non-linear patterns.  \n",
    "\n",
    "- **Dropout layers** for regularization and overfitting prevention.  \n",
    "\n",
    "- **Output layer** with a single neuron to predict the continuous xG value in [0,1].  \n",
    "\n",
    "The model is trained using the **Adam optimizer** and **Mean Squared Error (MSE)** loss, with **early stopping** applied to prevent overfitting.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c416eeb6",
   "metadata": {},
   "source": [
    "#### Imports and Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33414c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Ready to load data.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "\n",
    "# Display options\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.float_format\", lambda x: f\"{x:,.4f}\")\n",
    "\n",
    "# Output paths\n",
    "OUTPUT_DIR = \"../task1_xg/outputs\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Model directory\n",
    "MODEL_DIR = \"../task1_xg/models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Setup complete. Ready to load data.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2b1e7d",
   "metadata": {},
   "source": [
    "#### Load Dataset DS4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa3db70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 86833 rows, 26 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>period</th>\n",
       "      <th>shot_type</th>\n",
       "      <th>shot_technique</th>\n",
       "      <th>shot_body_part</th>\n",
       "      <th>play_pattern</th>\n",
       "      <th>under_pressure</th>\n",
       "      <th>shot_first_time</th>\n",
       "      <th>shot_one_on_one</th>\n",
       "      <th>target_xg</th>\n",
       "      <th>loc_x</th>\n",
       "      <th>loc_y</th>\n",
       "      <th>end_shot_x</th>\n",
       "      <th>end_shot_y</th>\n",
       "      <th>end_shot_z</th>\n",
       "      <th>end_shot_z_available</th>\n",
       "      <th>shot_from_set_piece</th>\n",
       "      <th>distance_to_goal</th>\n",
       "      <th>angle_to_goal</th>\n",
       "      <th>gender</th>\n",
       "      <th>role</th>\n",
       "      <th>num_players_between</th>\n",
       "      <th>closest_defender_dist</th>\n",
       "      <th>goalkeeper_positioning</th>\n",
       "      <th>free_proj_goal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.8136</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0566</td>\n",
       "      <td>0.7774</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.6561</td>\n",
       "      <td>0.4393</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.2143</td>\n",
       "      <td>0.1293</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3077</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.7132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0507</td>\n",
       "      <td>0.6780</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1434</td>\n",
       "      <td>0.9347</td>\n",
       "      <td>0.4166</td>\n",
       "      <td>0.9645</td>\n",
       "      <td>0.4456</td>\n",
       "      <td>0.1364</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0871</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.3670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0797</td>\n",
       "      <td>0.1356</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>0.8416</td>\n",
       "      <td>0.6964</td>\n",
       "      <td>0.8766</td>\n",
       "      <td>0.5845</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.2227</td>\n",
       "      <td>0.0865</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1538</td>\n",
       "      <td>0.0329</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.5547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0942</td>\n",
       "      <td>0.2712</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0528</td>\n",
       "      <td>0.9269</td>\n",
       "      <td>0.5910</td>\n",
       "      <td>0.8897</td>\n",
       "      <td>0.5845</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.5316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1159</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.6534</td>\n",
       "      <td>0.5295</td>\n",
       "      <td>0.6523</td>\n",
       "      <td>0.5156</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.3301</td>\n",
       "      <td>0.0872</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2308</td>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.7198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   minute  second  period  shot_type  shot_technique  shot_body_part  \\\n",
       "0  0.0435  0.8136       2          3               1               3   \n",
       "1  0.0507  0.6780       2          3               1               1   \n",
       "2  0.0797  0.1356       2          3               1               1   \n",
       "3  0.0942  0.2712       2          3               1               0   \n",
       "4  0.1159  0.0000       2          3               1               1   \n",
       "\n",
       "   play_pattern  under_pressure  shot_first_time  shot_one_on_one  target_xg  \\\n",
       "0             2           False             True            False     0.0566   \n",
       "1             1            True             True            False     0.1434   \n",
       "2             2           False             True            False     0.0382   \n",
       "3             2           False            False            False     0.0528   \n",
       "4             1            True            False            False     0.0213   \n",
       "\n",
       "   loc_x  loc_y  end_shot_x  end_shot_y  end_shot_z  end_shot_z_available  \\\n",
       "0 0.7774 0.4366      0.6561      0.4393      0.0000                 False   \n",
       "1 0.9347 0.4166      0.9645      0.4456      0.1364                  True   \n",
       "2 0.8416 0.6964      0.8766      0.5845      0.0000                 False   \n",
       "3 0.9269 0.5910      0.8897      0.5845      0.0000                 False   \n",
       "4 0.6534 0.5295      0.6523      0.5156      0.0000                 False   \n",
       "\n",
       "   shot_from_set_piece  distance_to_goal  angle_to_goal  gender  role  \\\n",
       "0                False            0.2143         0.1293       1     3   \n",
       "1                False            0.0871         0.2250       1     0   \n",
       "2                False            0.2227         0.0865       1     0   \n",
       "3                False            0.0995         0.1940       1     0   \n",
       "4                False            0.3301         0.0872       1     3   \n",
       "\n",
       "   num_players_between  closest_defender_dist  goalkeeper_positioning  \\\n",
       "0               0.3077                 0.0104                  0.0132   \n",
       "1               0.0769                 0.0079                  0.0123   \n",
       "2               0.1538                 0.0329                  0.0068   \n",
       "3               0.0769                 0.0071                  0.0045   \n",
       "4               0.2308                 0.0208                  0.0019   \n",
       "\n",
       "   free_proj_goal  \n",
       "0          0.7132  \n",
       "1          0.3670  \n",
       "2          0.5547  \n",
       "3          0.5316  \n",
       "4          0.7198  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"../task1_xg/data/DS4.csv\" \n",
    "ds4 = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Drop ID columns since they are not needed for modeling\n",
    "ds4 = ds4.drop(columns=['event_id', 'match_id', 'player_id'])\n",
    "\n",
    "print(f\"Dataset loaded: {ds4.shape[0]} rows, {ds4.shape[1]} columns\")\n",
    "ds4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fa2c85",
   "metadata": {},
   "source": [
    "####  Define features, target and train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa05f674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target (xG) stats:\n",
      "count   86,833.0000\n",
      "mean         0.0973\n",
      "std          0.1281\n",
      "min          0.0002\n",
      "25%          0.0275\n",
      "50%          0.0540\n",
      "75%          0.1060\n",
      "max          0.9951\n",
      "Name: target_xg, dtype: float64\n",
      "Range: 0.0002 - 0.9951\n",
      "\n",
      "Training set: 69466 rows\n",
      "Test set: 17367 rows\n"
     ]
    }
   ],
   "source": [
    "target_column = \"target_xg\"  # expected goals column\n",
    "train_columns = [col for col in ds4.columns if col != target_column]\n",
    "\n",
    "X = ds4[train_columns]\n",
    "y = ds4[target_column]\n",
    "\n",
    "# Sanity check on target\n",
    "print(\"\\nTarget (xG) stats:\")\n",
    "print(y.describe())\n",
    "print(f\"Range: {y.min():.4f} - {y.max():.4f}\")\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape[0]} rows\")\n",
    "print(f\"Test set: {X_test.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fc696c",
   "metadata": {},
   "source": [
    "#### Training the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc21a5d4",
   "metadata": {},
   "source": [
    "To extend the analysis to a neural approach, a **Multi-Layer Perceptron (MLP) Regressor** is trained on dataset DS4.  \n",
    "\n",
    "A **RandomizedSearchCV with 5-fold cross-validation** is employed to efficiently identify the best hyperparameters, optimizing for **Root Mean Squared Error (RMSE)** as the main evaluation metric.  \n",
    "\n",
    "Unlike GridSearchCV, RandomizedSearchCV samples only a fixed number of configurations from the defined search space. This approach makes the process faster and computationally lighter, while still exploring a diverse range of parameter combinations.  \n",
    "It therefore represents a **trade-off between exploration and efficiency**: the absolute best configuration may not be guaranteed, but the method provides a very good solution with far fewer evaluations, saving substantial time and resources.  \n",
    "\n",
    "The hyperparameters explored include:  \n",
    "\n",
    "- `hidden_layer_sizes`: architecture of the network, defining the number of neurons per hidden layer.  \n",
    "\n",
    "- `activation`: non-linear transformation applied at each neuron (`relu` or `tanh`).  \n",
    "\n",
    "- `alpha`: L2 regularization parameter, preventing overfitting by penalizing large weights.  \n",
    "\n",
    "- `learning_rate_init`: initial learning rate controlling the step size of weight updates.  \n",
    "\n",
    "- `solver`: optimization algorithm used for training (`adam` or `lbfgs`).  \n",
    "\n",
    "At the end of the search, the best model (`best_mlp`) is automatically retrained on the full training set with the selected hyperparameters, and is then used for prediction and evaluation on both the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36c6bb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time=  22.6s\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time=  24.4s\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time=  36.5s\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time=  37.3s\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time=  16.6s\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time=  45.9s\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time=  23.3s\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time=  59.6s\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time= 1.2min\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time= 1.5min\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(128,), learning_rate_init=0.001, solver=adam; total time=  55.5s\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(128,), learning_rate_init=0.001, solver=adam; total time=  59.0s\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(128,), learning_rate_init=0.01, solver=adam; total time=  31.2s\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(128,), learning_rate_init=0.01, solver=adam; total time=  50.5s\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(128,), learning_rate_init=0.001, solver=adam; total time= 1.5min\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(128,), learning_rate_init=0.01, solver=adam; total time=  55.4s\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(128,), learning_rate_init=0.01, solver=adam; total time=  55.5s\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(128,), learning_rate_init=0.01, solver=adam; total time= 1.1min\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(64, 32), learning_rate_init=0.001, solver=adam; total time= 1.1min\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(128,), learning_rate_init=0.001, solver=adam; total time= 2.2min\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(128,), learning_rate_init=0.001, solver=adam; total time= 2.6min\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(64, 32), learning_rate_init=0.01, solver=adam; total time=  35.2s\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(64, 32), learning_rate_init=0.01, solver=adam; total time=  42.6s\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(64, 32), learning_rate_init=0.001, solver=adam; total time= 1.9min\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(64, 32), learning_rate_init=0.001, solver=adam; total time= 2.4min\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(64, 32), learning_rate_init=0.001, solver=adam; total time= 1.9min\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(64, 32), learning_rate_init=0.01, solver=adam; total time= 1.6min\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(64, 32), learning_rate_init=0.01, solver=adam; total time= 1.4min\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(64, 32), learning_rate_init=0.01, solver=adam; total time= 1.8min\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(64, 32), learning_rate_init=0.001, solver=adam; total time= 2.8min\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(128, 64), learning_rate_init=0.01, solver=adam; total time= 1.6min\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(128, 64), learning_rate_init=0.001, solver=adam; total time= 2.7min\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(128, 64), learning_rate_init=0.001, solver=adam; total time= 3.3min\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(128, 64), learning_rate_init=0.01, solver=adam; total time= 2.3min\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(128, 64), learning_rate_init=0.001, solver=adam; total time= 3.3min\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(128, 64), learning_rate_init=0.01, solver=adam; total time= 2.2min\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(128, 64), learning_rate_init=0.001, solver=adam; total time= 3.2min\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(128, 64), learning_rate_init=0.01, solver=adam; total time= 1.2min\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(128, 64), learning_rate_init=0.001, solver=adam; total time= 3.7min\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time= 1.6min\n",
      "[CV] END activation=relu, alpha=1e-05, hidden_layer_sizes=(128, 64), learning_rate_init=0.01, solver=adam; total time= 2.4min\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time= 1.6min\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time=  38.9s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time=  46.8s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time= 1.8min\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time=  31.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time=  33.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time= 2.0min\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time=  57.6s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time= 2.1min\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128,), learning_rate_init=0.01, solver=adam; total time=  40.9s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128,), learning_rate_init=0.01, solver=adam; total time=  39.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128,), learning_rate_init=0.001, solver=adam; total time= 1.2min\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128,), learning_rate_init=0.01, solver=adam; total time= 1.1min\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128,), learning_rate_init=0.001, solver=adam; total time= 2.1min\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128,), learning_rate_init=0.01, solver=adam; total time= 1.1min\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128,), learning_rate_init=0.01, solver=adam; total time= 1.1min\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128,), learning_rate_init=0.001, solver=adam; total time= 2.4min\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate_init=0.001, solver=adam; total time= 1.4min\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128,), learning_rate_init=0.001, solver=adam; total time= 2.6min\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128,), learning_rate_init=0.001, solver=adam; total time= 2.9min\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate_init=0.01, solver=adam; total time=  32.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate_init=0.01, solver=adam; total time= 1.3min\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate_init=0.001, solver=adam; total time= 1.7min\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate_init=0.001, solver=adam; total time= 2.0min\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate_init=0.01, solver=adam; total time= 1.2min\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate_init=0.01, solver=adam; total time= 1.1min\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate_init=0.001, solver=adam; total time= 2.3min\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate_init=0.01, solver=adam; total time=  38.7s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate_init=0.001, solver=adam; total time= 2.0min\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate_init=0.01, solver=adam; total time= 1.2min\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate_init=0.01, solver=adam; total time= 1.8min\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate_init=0.01, solver=adam; total time= 1.8min\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate_init=0.001, solver=adam; total time= 2.5min\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate_init=0.001, solver=adam; total time= 3.2min\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate_init=0.001, solver=adam; total time= 3.3min\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate_init=0.001, solver=adam; total time= 3.3min\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate_init=0.01, solver=adam; total time= 1.4min\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate_init=0.001, solver=adam; total time= 3.6min\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time= 1.7min\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time= 1.8min\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time=  24.6s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate_init=0.01, solver=adam; total time= 2.8min\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time=  37.6s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time= 1.2min\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time= 1.1min\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time= 1.5min\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time=  45.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time=  47.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time= 1.7min\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128,), learning_rate_init=0.01, solver=adam; total time=  53.7s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128,), learning_rate_init=0.01, solver=adam; total time=  40.5s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128,), learning_rate_init=0.01, solver=adam; total time=  56.8s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128,), learning_rate_init=0.001, solver=adam; total time= 1.4min\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128,), learning_rate_init=0.001, solver=adam; total time= 1.9min\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128,), learning_rate_init=0.001, solver=adam; total time= 1.9min\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128,), learning_rate_init=0.001, solver=adam; total time= 1.9min\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128,), learning_rate_init=0.01, solver=adam; total time=  56.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128,), learning_rate_init=0.001, solver=adam; total time= 2.2min\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128,), learning_rate_init=0.01, solver=adam; total time=  53.8s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate_init=0.01, solver=adam; total time=  28.5s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate_init=0.01, solver=adam; total time=  32.0s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate_init=0.001, solver=adam; total time= 1.2min\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate_init=0.001, solver=adam; total time= 1.2min\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate_init=0.001, solver=adam; total time=  57.5s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate_init=0.01, solver=adam; total time=  56.9s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate_init=0.001, solver=adam; total time= 1.5min\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate_init=0.01, solver=adam; total time=  39.6s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate_init=0.01, solver=adam; total time=  58.2s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate_init=0.001, solver=adam; total time= 2.0min\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate_init=0.01, solver=adam; total time= 1.3min\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate_init=0.01, solver=adam; total time= 1.2min\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate_init=0.01, solver=adam; total time= 1.4min\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate_init=0.001, solver=adam; total time= 2.8min\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate_init=0.001, solver=adam; total time= 2.8min\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate_init=0.001, solver=adam; total time= 2.9min\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate_init=0.001, solver=adam; total time= 2.9min\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate_init=0.01, solver=adam; total time= 1.5min\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate_init=0.01, solver=adam; total time= 1.9min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time=  30.2s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate_init=0.001, solver=adam; total time= 3.9min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time=  41.2s\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time= 1.8min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time= 2.3min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time=  39.3s\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time= 1.1min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time= 2.4min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time= 2.1min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time= 2.7min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time= 1.2min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(128,), learning_rate_init=0.01, solver=adam; total time=  49.9s\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(128,), learning_rate_init=0.01, solver=adam; total time= 1.1min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(128,), learning_rate_init=0.001, solver=adam; total time= 1.3min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(128,), learning_rate_init=0.01, solver=adam; total time= 1.2min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(128,), learning_rate_init=0.001, solver=adam; total time= 2.3min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(128,), learning_rate_init=0.001, solver=adam; total time= 2.9min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(128,), learning_rate_init=0.01, solver=adam; total time= 1.2min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(128,), learning_rate_init=0.001, solver=adam; total time= 2.9min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(128,), learning_rate_init=0.01, solver=adam; total time= 1.5min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(64, 32), learning_rate_init=0.001, solver=adam; total time= 1.4min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(64, 32), learning_rate_init=0.01, solver=adam; total time=  39.9s\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(64, 32), learning_rate_init=0.001, solver=adam; total time= 1.8min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(64, 32), learning_rate_init=0.001, solver=adam; total time= 1.2min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(64, 32), learning_rate_init=0.001, solver=adam; total time= 1.9min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(64, 32), learning_rate_init=0.01, solver=adam; total time= 1.1min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(64, 32), learning_rate_init=0.001, solver=adam; total time= 1.2min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(128,), learning_rate_init=0.001, solver=adam; total time= 4.2min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(64, 32), learning_rate_init=0.01, solver=adam; total time= 1.0min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(64, 32), learning_rate_init=0.01, solver=adam; total time= 1.2min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(64, 32), learning_rate_init=0.01, solver=adam; total time= 1.1min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(128, 64), learning_rate_init=0.01, solver=adam; total time= 1.0min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(128, 64), learning_rate_init=0.001, solver=adam; total time= 2.4min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(128, 64), learning_rate_init=0.01, solver=adam; total time= 1.6min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(128, 64), learning_rate_init=0.001, solver=adam; total time= 2.2min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(128, 64), learning_rate_init=0.01, solver=adam; total time= 1.6min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(128, 64), learning_rate_init=0.001, solver=adam; total time= 2.3min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(128, 64), learning_rate_init=0.001, solver=adam; total time= 2.8min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(128, 64), learning_rate_init=0.01, solver=adam; total time= 1.2min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(128, 64), learning_rate_init=0.001, solver=adam; total time= 2.8min\n",
      "[CV] END activation=tanh, alpha=1e-05, hidden_layer_sizes=(128, 64), learning_rate_init=0.01, solver=adam; total time= 1.0min\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time= 1.4min\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time=  43.9s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time=  50.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time=  29.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time= 1.9min\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time= 1.3min\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time= 1.8min\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time= 2.1min\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time= 2.3min\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time=  50.1s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128,), learning_rate_init=0.01, solver=adam; total time=  28.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128,), learning_rate_init=0.01, solver=adam; total time=  47.1s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128,), learning_rate_init=0.001, solver=adam; total time= 1.2min\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128,), learning_rate_init=0.01, solver=adam; total time=  53.0s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128,), learning_rate_init=0.001, solver=adam; total time= 1.8min\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128,), learning_rate_init=0.01, solver=adam; total time= 1.2min\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128,), learning_rate_init=0.01, solver=adam; total time= 1.4min\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128,), learning_rate_init=0.001, solver=adam; total time= 2.6min\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128,), learning_rate_init=0.001, solver=adam; total time= 2.8min\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate_init=0.001, solver=adam; total time= 1.8min\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128,), learning_rate_init=0.001, solver=adam; total time= 3.1min\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate_init=0.001, solver=adam; total time= 1.4min\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate_init=0.01, solver=adam; total time=  41.7s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate_init=0.01, solver=adam; total time=  47.1s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate_init=0.001, solver=adam; total time= 1.2min\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate_init=0.001, solver=adam; total time= 2.2min\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate_init=0.01, solver=adam; total time=  51.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate_init=0.01, solver=adam; total time=  48.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate_init=0.001, solver=adam; total time= 1.8min\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(64, 32), learning_rate_init=0.01, solver=adam; total time=  55.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate_init=0.01, solver=adam; total time= 1.0min\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate_init=0.01, solver=adam; total time= 1.3min\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate_init=0.01, solver=adam; total time= 1.5min\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate_init=0.001, solver=adam; total time= 2.4min\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate_init=0.001, solver=adam; total time= 2.4min\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate_init=0.01, solver=adam; total time= 1.2min\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate_init=0.001, solver=adam; total time= 3.0min\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate_init=0.01, solver=adam; total time= 1.1min\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate_init=0.001, solver=adam; total time= 3.3min\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time=  52.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time= 1.3min\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time=  15.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time=  45.7s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time=  26.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time=  35.8s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64,), learning_rate_init=0.01, solver=adam; total time=  30.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128,), learning_rate_init=0.001, solver=adam; total time=  40.8s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time= 2.1min\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time= 2.5min\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64,), learning_rate_init=0.001, solver=adam; total time= 2.3min\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(128, 64), learning_rate_init=0.001, solver=adam; total time= 4.7min\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128,), learning_rate_init=0.01, solver=adam; total time=  29.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128,), learning_rate_init=0.01, solver=adam; total time=  38.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128,), learning_rate_init=0.01, solver=adam; total time=  58.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128,), learning_rate_init=0.01, solver=adam; total time=  49.9s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128,), learning_rate_init=0.001, solver=adam; total time= 2.2min\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128,), learning_rate_init=0.001, solver=adam; total time= 2.5min\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128,), learning_rate_init=0.01, solver=adam; total time=  52.6s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate_init=0.01, solver=adam; total time=  35.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128,), learning_rate_init=0.001, solver=adam; total time= 2.6min\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate_init=0.001, solver=adam; total time= 1.2min\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128,), learning_rate_init=0.001, solver=adam; total time= 3.0min\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate_init=0.001, solver=adam; total time= 1.5min\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate_init=0.001, solver=adam; total time= 1.3min\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate_init=0.01, solver=adam; total time=  36.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate_init=0.01, solver=adam; total time=  42.6s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate_init=0.001, solver=adam; total time= 1.6min\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate_init=0.01, solver=adam; total time=  40.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate_init=0.01, solver=adam; total time=  43.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 32), learning_rate_init=0.001, solver=adam; total time= 2.0min\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate_init=0.01, solver=adam; total time= 1.1min\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate_init=0.01, solver=adam; total time= 1.2min\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate_init=0.01, solver=adam; total time= 1.4min\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate_init=0.001, solver=adam; total time= 2.1min\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate_init=0.01, solver=adam; total time= 1.0min\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate_init=0.01, solver=adam; total time= 1.0min\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate_init=0.001, solver=adam; total time= 3.0min\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate_init=0.001, solver=adam; total time= 2.9min\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate_init=0.001, solver=adam; total time= 2.7min\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(128, 64), learning_rate_init=0.001, solver=adam; total time= 3.2min\n",
      "\n",
      "Best parameters found: {'solver': 'adam', 'learning_rate_init': 0.001, 'hidden_layer_sizes': (128, 64), 'alpha': 1e-05, 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Base model\n",
    "mlp = MLPRegressor(\n",
    "    max_iter=1000,                 # Maximum number of iterations\n",
    "    early_stopping=True,           # Stop training when validation score is not improving\n",
    "    random_state=RANDOM_STATE      # Reproducibility\n",
    ")\n",
    "\n",
    "# Parameter grid\n",
    "param_dist = {\n",
    "    \"hidden_layer_sizes\": [(64,), (128,), (64, 32), (128, 64)],\n",
    "    \"activation\": [\"relu\", \"tanh\"],\n",
    "    \"alpha\": [1e-5, 1e-4, 1e-3],          # L2 regularization\n",
    "    \"learning_rate_init\": [0.001, 0.01],  # initial learning rate\n",
    "    \"solver\": [\"adam\"]           # optimizers\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV\n",
    "rand_search = RandomizedSearchCV(\n",
    "    estimator=mlp,                          # MLP model\n",
    "    param_distributions=param_dist,         # parameter distributions for hyperparameter tuning\n",
    "    n_iter=100,                             # number of random combinations to try\n",
    "    scoring=\"neg_root_mean_squared_error\",  # RMSE as main metric (neg because of sklearn convention)\n",
    "    cv=5,                                   # cross-validation splitting strategy\n",
    "    random_state=RANDOM_STATE,              # reproducibility\n",
    "    n_jobs=-1,                              # parallelization\n",
    "    verbose=2                               # verbosity level, defines the amount of information displayed during training\n",
    ")\n",
    "\n",
    "# Fit\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_mlp = rand_search.best_estimator_\n",
    "print(\"\\nBest parameters found:\", rand_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce1199f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(y_true, y_pred, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Evaluate regression performance using a set of metrics\n",
    "    suitable for probabilistic xG estimation (continuous target in [0, 1]).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like\n",
    "        Ground truth (true xG values).\n",
    "    y_pred : array-like\n",
    "        Predicted xG values.\n",
    "    model_name : str\n",
    "        Label to display in output.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    metrics : dict\n",
    "        Dictionary of metric values.\n",
    "    \"\"\"\n",
    "\n",
    "    metrics = {\n",
    "        # Root Mean Squared Error (RMSE):\n",
    "        # sqrt( (1/n) *  (y_i - _i)^2 )\n",
    "        # Penalizes large errors more strongly; same units as target.\n",
    "        \"RMSE\": root_mean_squared_error(y_true, y_pred),\n",
    "\n",
    "        # Mean Absolute Error (MAE):\n",
    "        # (1/n) *  |y_i - _i|\n",
    "        # Robust to outliers; easy to interpret as \"average absolute error\".\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "\n",
    "        # Coefficient of Determination (R):\n",
    "        # 1 - ( (y_i - _i)^2) / ( (y_i - )^2)\n",
    "        # Measures proportion of variance explained by the model.\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "\n",
    "        # Pearson Correlation Coefficient:\n",
    "        # cov(y, ) / (_y * _)\n",
    "        # Measures strength of linear relationship between y_true and y_pred.\n",
    "        \"Pearson\": pearsonr(y_true, y_pred)[0],\n",
    "\n",
    "        # Spearman Rank Correlation:\n",
    "        # Pearson correlation between rank(y) and rank()\n",
    "        # Captures monotonic (not necessarily linear) relationships.\n",
    "        \"Spearman\": spearmanr(y_true, y_pred)[0]\n",
    "    }\n",
    "\n",
    "    # Print nicely formatted results\n",
    "    print(f\"\\n{model_name} performance:\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"{k:>12}: {v:.4f}\")\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a319f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neural Network (train) performance:\n",
      "        RMSE: 0.0368\n",
      "         MAE: 0.0199\n",
      "          R2: 0.9165\n",
      "     Pearson: 0.9574\n",
      "    Spearman: 0.9566\n",
      "\n",
      "Neural Network (test) performance:\n",
      "        RMSE: 0.0427\n",
      "         MAE: 0.0217\n",
      "          R2: 0.8936\n",
      "     Pearson: 0.9456\n",
      "    Spearman: 0.9554\n"
     ]
    }
   ],
   "source": [
    "# Predict on train/test\n",
    "y_train_pred = best_mlp.predict(X_train)\n",
    "y_test_pred  = best_mlp.predict(X_test)\n",
    "\n",
    "# Evaluate with the same function used across models\n",
    "train_metrics = evaluate_predictions(y_train, y_train_pred, \"Neural Network (train)\")\n",
    "test_metrics  = evaluate_predictions(y_test,  y_test_pred,  \"Neural Network (test)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a25c28",
   "metadata": {},
   "source": [
    "#### Features Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc8766c",
   "metadata": {},
   "source": [
    "Unlike Linear Regression, Random Forest, or XGBoost, a **Neural Network does not provide a straightforward feature importance measure**. The weights of the network cannot be directly interpreted as feature contributions, since they are distributed across multiple layers and transformed by non-linear activation functions.  \n",
    "\n",
    "For consistency and interpretability, **feature importance will only be reported for models that natively support it** (Linear Regression, Random Forest, XGBoost). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee0b39c",
   "metadata": {},
   "source": [
    "#### Save results and trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46a4d839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to ../task1_xg/outputs/metrics_nn.csv\n",
      "Model saved to ../task1_xg/models/model_nn.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Save metrics\n",
    "results_df = pd.DataFrame(\n",
    "    [train_metrics, test_metrics],\n",
    "    index=[\"Neural Network (train)\", \"Neural Network (test)\"]\n",
    ")\n",
    "results_df.to_csv(f\"{OUTPUT_DIR}/metrics_nn.csv\", index=True)\n",
    "\n",
    "# Save model\n",
    "model_path = f\"{MODEL_DIR}/model_nn.pkl\"\n",
    "joblib.dump(best_mlp, model_path)\n",
    "\n",
    "print(f\"Metrics saved to {OUTPUT_DIR}/metrics_nn.csv\")\n",
    "print(f\"Model saved to {model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f414a61b",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e12f433",
   "metadata": {},
   "source": [
    "The **Neural Network (MLP Regressor)** achieved solid performance on both the training and test sets.  \n",
    "On the **training set**, the model reached an **RMSE of 0.0368** and an **R of 0.9165**, showing that it was able to capture most of the variance in the data.  \n",
    "On the **test set**, the performance slightly decreased to an **RMSE of 0.0427** and an **R of 0.8936**, indicating a little performance drop but still strong generalization capabilities.  \n",
    "\n",
    "Correlation metrics further confirm the models robustness: both **Pearson (0.9456)** and **Spearman (0.9554)** remain high on the test set, suggesting that the Neural Network preserves the correct ranking of predictions and maintains consistency with the true target distribution.  \n",
    "\n",
    "Overall, the Neural Network performs **competitively compared to ensemble methods (Random Forest, XGBoost)**, striking a good balance between training accuracy and test generalization, with only a modest degree of overfitting.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
